{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> <p align=\"center\"> <span style=\"color: #DCC43C\"> PYTORCH EXPERIMENT TRACKING <span> </p> </b>\n",
    "### <b> <p align=\"center\"> <span style=\"color: #BFF0FF\"> let's explore <span> </p> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is experimental . \n",
    "\n",
    "To know which experments are worth pursuing that's where **Experimental tracking** comes in to figure out what doesn't work so you can figure out what does work.\n",
    "\n",
    "In this notebook, we're going to see an example fo programmatically tracking experiments\n",
    "\n",
    "And so far we've keep track of them via Python dictionaries.\n",
    "\n",
    "Or just comparing them by the metric print outs during training.\n",
    "\n",
    "What if you wanted to run a dozen (or more) different models at once?\n",
    "\n",
    "Surely there's a better way...\n",
    "\n",
    "There is.\n",
    "\n",
    "**Experiment tracking.**\n",
    "\n",
    "And since experiment tracking is so important and integral to machine learning, you can consider this notebook your first milestone project.\n",
    "\n",
    "So welcome to Milestone Project 1: FoodVision Mini Experiment Tracking.\n",
    "\n",
    "We're going to answer the question: **how do I track my machine learning experiments?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why track experiments?\n",
    "\n",
    "If you're only running a handful of models (like we've done so far), it might be okay just to track their results in print outs and a few dictionaries.\n",
    "\n",
    "However, as the number of experiments you run starts to increase, this naive way of tracking could get out of hand.\n",
    "\n",
    "So if you're following the machine learning practitioner's motto of *experiment, experiment, experiment!*, you'll want a way to track them.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/07-experiment-tracking-can-get-out-of-hand.png\" alt=\"experiment tracking can get out of hand, many different experiments with different names\" width=900/>\n",
    "\n",
    "*After building a few models and tracking their results, you'll start to notice how quickly it can get out of hand.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different ways to track machine learning experiments\n",
    "\n",
    "There are as many different ways to track machine learning experiments as there is experiments to run.\n",
    "\n",
    "This table covers a few.\n",
    "\n",
    "| **Method** | **Setup** | **Pros** | **Cons** | **Cost** |\n",
    "| ----- | ----- | ----- | ----- | ----- |\n",
    "| Python dictionaries, CSV files, print outs | None | Easy to setup, runs in pure Python | Hard to keep track of large numbers of experiments | Free |\n",
    "| [TensorBoard](https://www.tensorflow.org/tensorboard/get_started) | Minimal, install [`tensorboard`](https://pypi.org/project/tensorboard/) | Extensions built into PyTorch, widely recognized and used, easily scales. | User-experience not as nice as other options. | Free |\n",
    "| [Weights & Biases Experiment Tracking](https://wandb.ai/site/experiment-tracking) | Minimal, install [`wandb`](https://docs.wandb.ai/quickstart), make an account | Incredible user experience, make experiments public, tracks almost anything. | Requires external resource outside of PyTorch. | Free for personal use |\n",
    "| [MLFlow](https://mlflow.org/) | Minimal, install `mlflow` and starting tracking | Fully open-source MLOps lifecycle management, many integrations. | Little bit harder to setup a remote tracking server than other services. | Free |\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/07-different-places-to-track-experiments.png\" alt=\"various places to track machine learning experiments\" width=900/>\n",
    "\n",
    "*Various places and techniques you can use to track your machine learning experiments. **Note:** There are various other options similar to Weights & Biases and open-source options similar to MLflow but I've left them out for brevity. You can find more by searching \"machine learning experiment tracking\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Getting Setup \n",
    "\n",
    "Going moduler [section](https://github.com/ShafaetUllah032/DL_with_PyTorch/tree/main/going_modular) will be needed here.\n",
    "We'll also get the [`torchinfo`](https://github.com/TylerYep/torchinfo) package if it's not available.\n",
    "\n",
    "`torchinfo` will help later on to give us visual summaries of our model(s).\n",
    "\n",
    "And since we're using a newer version of the `torchvision` package (v0.13 as of June 2022), we'll make sure we've got the latest versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0 0.18.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__, torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have required version ... no need to download\n",
    "\n",
    "If you have the lower version then, \n",
    "\n",
    "```\n",
    "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
    "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
    "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with regular imports\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Try to get torchinfo, install it if it doesn't work\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's setup device agnostic code.\n",
    "\n",
    "> **Note:** If you're using Google Colab, and you don't have a GPU turned on yet, it's now time to turn one on via `Runtime -> Change runtime type -> Hardware accelerator -> GPU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a helper function to set seeds\n",
    "\n",
    "Since we've been setting random seeds a whole bunch throughout previous sections, how about we functionize it?\n",
    "\n",
    "Let's create a function to \"set the seeds\" called `set_seeds()`.\n",
    "\n",
    "> **Note:** Recall a [random seed](https://en.wikipedia.org/wiki/Random_seed) is a way of flavouring the randomness generated by a computer. They aren't necessary to always set when running machine learning code, however, they help ensure there's an element of reproducibility (the numbers I get with my code are similar to the numbers you get with your code). Outside of an education or experimental setting, random seeds generally aren't required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data \n",
    "\n",
    "As always , before we can run machine learning experimnets, we will need a dataset\n",
    "\n",
    "We're going to continue trying to improve upon the results we've been getting on Foobvision Mini.\n",
    "\n",
    "In the last notebook we saw how powerful the transfer learning is. Let's do something expermnetal do improve the result.\n",
    "\n",
    "Let's goo....\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_exists , skip creating .....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(WindowsPath('for experiment tracking/food_data/train'),\n",
       " WindowsPath('for experiment tracking/food_data/test'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from going_modular import get_data\n",
    "\n",
    "train_path,test_path=get_data.get_data(path=\"for experiment tracking\",\n",
    "                                       sub_folder=\"food_data\",\n",
    "                                       url=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "train_path, test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got our data , let's go for experiments and track the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Dataset and dataloader\n",
    "\n",
    "As we have the data, to train and test , We have to convert them into the dataloader.\n",
    "\n",
    "We can do by using the `create_dataloader` function from `going_moduler.datasetup` from [going moduder](https://github.com/ShafaetUllah032/DL_with_PyTorch/tree/main/going_modular)\n",
    "\n",
    "And since we'll be using transfer learning and specifically pretrained models from [`torchvision.models`](https://pytorch.org/vision/stable/models.html), we'll create a transform to prepare our images correctly.\n",
    "\n",
    "To transform our images in tensors, we can use:\n",
    "1. Manually created transforms using `torchvision.transforms`.\n",
    "2. Automatically created transforms using `torchvision.models.MODEL_NAME.MODEL_WEIGHTS.DEFAULT.transforms()`.\n",
    "    * Where `MODEL_NAME` is a specific `torchvision.models` architecture, `MODEL_WEIGHTS` is a specific set of pretrained weights and `DEFAULT` means the \"best available weights\".\n",
    "    \n",
    "do did it at [transfer learning](https://github.com/ShafaetUllah032/DL_with_PyTorch/blob/main/06%20pytorch%20tranfer%20learning.ipynb) section\n",
    "\n",
    "Let's see first an example of manually creating a `torchvision.transforms` pipeline (creating a transforms pipeline this way gives the most customization but can potentially result in performance degradation if the transforms don't match the pretrained model).\n",
    "\n",
    "The main manual transformation we need to be sure of is that all of our images are normalized in ImageNet format (this is because pretrained `torchvision.models` are all pretrained on [ImageNet](https://www.image-net.org/)).\n",
    "\n",
    "We can do this with:\n",
    "\n",
    "```python\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create DataLoaders using manually created transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually created transforms: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1a293ea35b0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1a293ecba90>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the module\n",
    "\n",
    "from going_modular import data_setup\n",
    "from torchvision import transforms\n",
    "\n",
    "# Setup ImageNet normalization levels (turns all images into similar distribution as ImageNet)\n",
    "normalize=transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Create transform pipeline manually\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "print(f\"Manually created transforms: {manual_transforms}\")\n",
    "\n",
    "\n",
    "train_dataloader,test_dataloader,class_names=data_setup.create_dataloaders(train_dir=train_path,\n",
    "                                                                           test_dir=test_path,\n",
    "                                                                           transform=manual_transforms,\n",
    "                                                                           batch_size=32)\n",
    "\n",
    "train_dataloader,test_dataloader,class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create DataLoaders using automatically created transforms\n",
    "\n",
    "Datatransfomr and DataLoader created !\n",
    "\n",
    "We are going to create dataloader using automatics process \n",
    "We can do this by first instantiating a set of pretrained weights (for example `weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT`)  we'd like to use and calling the `transforms()` method on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automatically created transforms :ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1a293ecb6d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1a293ecb9d0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup pretrained weights (plenty of these available in torchvision.models)\n",
    "\n",
    "weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# Get transform from weight(these are the transform that were used to obtain the weights)\n",
    "automatic_transform=weights.transforms()\n",
    "print(f\"automatically created transforms :{automatic_transform}\")\n",
    "\n",
    "train_dataloader,test_dataloader,class_names=data_setup.create_dataloaders(train_dir=train_path,\n",
    "                                                                           test_dir=test_path,\n",
    "                                                                           transform=automatic_transform,\n",
    "                                                                           batch_size=32)\n",
    "\n",
    "train_dataloader,test_dataloader,class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting a pretrained model , freezing the base layers and changing the classifier head\n",
    "\n",
    "Before we run an track multiple modeling experiments, let's see what it's like to run and track a single one And since our data is ready, the next thing we'll need a model.\n",
    "Let's download the pretrained weights for a `torchvision.models.efficientnet_b0()` model and prepare it for use with our own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchWithCuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
